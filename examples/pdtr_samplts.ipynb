{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cairosvg\n",
    "import dtreeviz\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from openpyxl.utils import get_column_letter, column_index_from_string\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import _tree, DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "\n",
    "try:\n",
    "    from pdtr import ParseDecisionTreeRules, ExcelWriter\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    \n",
    "    sys.path.append(\"../\")\n",
    "    from pdtr import ParseDecisionTreeRules, ExcelWriter\n",
    "    \n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEXBASE_X291_4</th>\n",
       "      <th>GEXBASE_X46_6</th>\n",
       "      <th>GEXGDJK_X264</th>\n",
       "      <th>GEXvar0230</th>\n",
       "      <th>GEXBASE_X19</th>\n",
       "      <th>GEXDK_X1648</th>\n",
       "      <th>GEXBASE_X253</th>\n",
       "      <th>GEX_var0019</th>\n",
       "      <th>GEXBASE_X70</th>\n",
       "      <th>GEXDK_X408</th>\n",
       "      <th>...</th>\n",
       "      <th>GEXBASE_X191</th>\n",
       "      <th>GEXvar0255</th>\n",
       "      <th>GEXvar0163</th>\n",
       "      <th>GEXBASE_X270</th>\n",
       "      <th>GEXDK_X708</th>\n",
       "      <th>GEXvar0234</th>\n",
       "      <th>GEXvar0038</th>\n",
       "      <th>GEXJH_X40_20</th>\n",
       "      <th>GEXvar0013</th>\n",
       "      <th>TARGET_EVER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>未婚</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>未婚</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>未婚</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2558.652174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>已婚</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>3183.652174</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>已婚</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GEXBASE_X291_4  GEXBASE_X46_6  GEXGDJK_X264   GEXvar0230  GEXBASE_X19  \\\n",
       "0             2.0            NaN           NaN     0.000000          0.0   \n",
       "1            21.0            NaN           NaN          NaN          3.0   \n",
       "2             2.0            NaN           NaN          NaN          0.0   \n",
       "3             0.0            NaN           NaN  2558.652174          0.0   \n",
       "4             2.0            NaN           NaN    66.500000          0.0   \n",
       "\n",
       "   GEXDK_X1648  GEXBASE_X253  GEX_var0019  GEXBASE_X70  GEXDK_X408  ...  \\\n",
       "0          1.0           0.0          0.0          3.0        52.0  ...   \n",
       "1         36.0           0.0          0.0         41.0        76.0  ...   \n",
       "2          NaN           0.0          NaN          3.0         NaN  ...   \n",
       "3          0.0           0.0          0.0          1.0        32.0  ...   \n",
       "4          0.0           0.0          0.0          1.0        53.0  ...   \n",
       "\n",
       "   GEXBASE_X191  GEXvar0255  GEXvar0163  GEXBASE_X270  GEXDK_X708  \\\n",
       "0            未婚         0.0         NaN           2.0         0.0   \n",
       "1            未婚         0.0         NaN          22.0      2300.0   \n",
       "2            未婚         NaN         NaN           2.0         NaN   \n",
       "3            已婚         0.0         NaN           0.0     15000.0   \n",
       "4            已婚         0.0         NaN           1.0      1150.0   \n",
       "\n",
       "    GEXvar0234  GEXvar0038  GEXJH_X40_20  GEXvar0013  TARGET_EVER  \n",
       "0     0.000000         1.0           0.0         NaN            0  \n",
       "1          NaN        16.0           0.0         NaN            0  \n",
       "2          NaN         NaN           0.0         NaN            0  \n",
       "3  3183.652174         2.0           0.0         NaN            0  \n",
       "4    66.500000         NaN           0.0         NaN            0  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"./scorecard_examples.pkl\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = \"target\"\n",
    "# feature_map = {}\n",
    "# n_samples = 1000\n",
    "# ab = np.array(list('ABCDEFG'))\n",
    "\n",
    "# data = pd.DataFrame({\n",
    "#     'A': np.random.randint(10, size = n_samples),\n",
    "#     'B': ab[np.random.choice(7, n_samples)],\n",
    "#     'C': ab[np.random.choice(2, n_samples)],\n",
    "#     'D': np.random.random(size = n_samples),\n",
    "#     'target': np.random.randint(2, size = n_samples)\n",
    "# })\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"TARGET_EVER\"\n",
    "train, test = train_test_split(data, test_size=0.3, shuffle=data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseDecisionTreeRules:\n",
    "    \n",
    "    def __init__(self, target=\"target\", labels=[\"positive\", \"negative\"], feature_map={}, nan=-1., max_iter=128, output=\"model_report/决策树组合策略挖掘.xlsx\", writer=None):\n",
    "        self.target = target\n",
    "        self.labels = labels\n",
    "        self.feature_map = feature_map\n",
    "        self.nan = nan\n",
    "        self.max_iter = max_iter\n",
    "        self.output = output\n",
    "        self.decision_trees = []\n",
    "        self.target_enc = None\n",
    "        self.feature_names = None\n",
    "        self.dt_rules = pd.DataFrame()\n",
    "        self.end_row = 2\n",
    "        self.start_col = 2\n",
    "        self.describe_columns = [\"组合策略\", \"命中数\", \"命中率\", \"好样本数\", \"好样本占比\", \"坏样本数\", \"坏样本占比\", \"坏率\", \"样本整体坏率\", \"LIFT值\"]\n",
    "        \n",
    "        if output:\n",
    "            if writer:\n",
    "                self.writer = writer\n",
    "            else:\n",
    "                self.writer = ExcelWriter(theme_color=\"2639E9\")\n",
    "            \n",
    "            self.worksheet = self.writer.get_sheet_by_name(\"决策树组合策略挖掘\")\n",
    "    \n",
    "    def encode_cat_features(self, X, y):\n",
    "        cat_features = list(set(X.select_dtypes(include=[object, pd.CategoricalDtype]).columns))\n",
    "        cat_features_index = [i for i, f in enumerate(X.columns) if f in cat_features]\n",
    "        \n",
    "        if len(cat_features) > 0:\n",
    "            if self.target_enc is None:\n",
    "                self.target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "                self.target_enc.fit(X[cat_features], y)\n",
    "                self.target_enc.target_mapping = {}\n",
    "                X_TE = X.join(self.target_enc.transform(X[cat_features]).add_suffix('_target'))\n",
    "                for col in cat_features:\n",
    "                    mapping = X_TE[[col, f\"{col}_target\"]].drop_duplicates()\n",
    "                    self.target_enc.target_mapping[col] = dict(zip(mapping[col], mapping[f\"{col}_target\"]))\n",
    "            else:\n",
    "                X_TE = X.join(self.target_enc.transform(X[cat_features]).add_suffix('_target'))\n",
    "            \n",
    "            X_TE = X_TE.drop(columns=cat_features)\n",
    "            return X_TE.rename(columns={f\"{c}_target\": c for c in cat_features})\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "    def get_dt_rules(self, tree, feature_names, total_bad_rate, total_count):\n",
    "        tree_ = tree.tree_\n",
    "        left = tree.tree_.children_left\n",
    "        right = tree.tree_.children_right\n",
    "        feature_name = [feature_names[i] if i != -2 else \"undefined!\" for i in tree_.feature]\n",
    "        rules=dict()\n",
    "\n",
    "        global res_df\n",
    "        res_df = pd.DataFrame()\n",
    "\n",
    "        def recurse(node, depth, parent): # 搜每个节点的规则\n",
    "\n",
    "            if tree_.feature[node] != -2:  # 非叶子节点,搜索每个节点的规则\n",
    "                name = feature_name[node]\n",
    "                thd = np.round(tree_.threshold[node],3)\n",
    "                s= \"{} <= {} \".format( name, thd, node )\n",
    "                # 左子\n",
    "                if node == 0:\n",
    "                    rules[node]=s\n",
    "                else:\n",
    "                    rules[node]=rules[parent]+' & ' +s\n",
    "                recurse(left[node], depth + 1, node)\n",
    "                s=\"{} > {}\".format(name, thd)\n",
    "                # 右子 \n",
    "                if node == 0:\n",
    "                    rules[node]=s\n",
    "                else:\n",
    "                    rules[node]=rules[parent]+' & ' +s\n",
    "                recurse(right[node], depth + 1, node)\n",
    "            else:\n",
    "                df = pd.DataFrame()\n",
    "                df['组合策略'] = rules[parent],\n",
    "                df['好样本数'] = tree_.value[node][0][0].astype(int)\n",
    "                df['好样本占比'] = df['好样本数'] / (total_count * (1 - total_bad_rate))\n",
    "                df['坏样本数'] = tree_.value[node][0][1].astype(int)\n",
    "                df['坏样本占比'] = df['坏样本数'] / (total_count * total_bad_rate)\n",
    "                df['命中数'] = df['好样本数'] + df['坏样本数']\n",
    "                df['命中率'] = df['命中数'] / total_count\n",
    "                df['坏率'] = df['坏样本数'] / df['命中数']\n",
    "                df['样本整体坏率'] = total_bad_rate\n",
    "                df['LIFT值'] = df['坏率'] / df['样本整体坏率']\n",
    "\n",
    "                global res_df\n",
    "\n",
    "                res_df = pd.concat([res_df, df], 0)\n",
    "\n",
    "        recurse(0, 1, 0)\n",
    "\n",
    "        return res_df.sort_values(\"LIFT值\", ascending=True)[self.describe_columns].reset_index(drop=True)\n",
    "    \n",
    "    def select_dt_rules(self, decision_tree, x, y, lift=3., max_samples=0.05, labels=[\"positive\", \"negative\"], save=None, verbose=False, drop=False):\n",
    "        rules = self.get_dt_rules(decision_tree, x.columns, sum(y) / len(y), len(y))\n",
    "        viz_model = dtreeviz.model(decision_tree,\n",
    "                                   X_train=x, \n",
    "                                   y_train=y,\n",
    "                                   feature_names=x.columns,\n",
    "                                   target_name=target, \n",
    "                                   class_names=labels,\n",
    "                                  )\n",
    "        print(rules)\n",
    "        rules = rules.query(f\"LIFT值 >= {lift} & 命中率 <= {max_samples}\").reset_index(drop=True)\n",
    "\n",
    "        if len(rules) > 0:\n",
    "            decision_tree_viz = viz_model.view(\n",
    "                                                scale=1.5, \n",
    "                                                orientation='LR', \n",
    "                                                colors={\n",
    "                                                        \"classes\": [None, None, [\"#2639E9\", \"#F76E6C\"], [\"#2639E9\", \"#F76E6C\", \"#FE7715\", \"#FFFFFF\"]],\n",
    "                                                        \"arrow\": \"#2639E9\",\n",
    "                                                        'text_wedge': \"#F76E6C\",\n",
    "                                                        \"pie\": \"#2639E9\",\n",
    "                                                        \"tile_alpha\": 1,\n",
    "                                                        \"legend_edge\": \"#FFFFFF\",\n",
    "                                                    },\n",
    "                                                ticks_fontsize=10,\n",
    "                                                label_fontsize=10,\n",
    "                                            )\n",
    "            if verbose:\n",
    "                if self.feature_map is not None and len(self.feature_map) > 0:\n",
    "                    print(rules.replace(self.feature_map, regex=True))\n",
    "                else:\n",
    "                    print(rules)\n",
    "            if save:\n",
    "                if os.path.dirname(save) and not os.path.exists(os.path.dirname(save)):\n",
    "                    os.makedirs(os.path.dirname(save))\n",
    "\n",
    "                decision_tree_viz.save(\"combine_rules_cache.svg\")\n",
    "                cairosvg.svg2png(url=\"combine_rules_cache.svg\", write_to=save, dpi=240)\n",
    "\n",
    "        if drop:\n",
    "            return rules, decision_tree.feature_names_in_[list(decision_tree.feature_importances_).index(max(decision_tree.feature_importances_))]\n",
    "        else:\n",
    "            return rules\n",
    "    \n",
    "    def query_dt_rules(self, x, y, parsed_rules=None):\n",
    "        total_count = len(y)\n",
    "        total_bad_rate = y.sum() / len(y)\n",
    "\n",
    "        rules = pd.DataFrame()\n",
    "        for rule in parsed_rules[\"组合策略\"].unique():\n",
    "            select_index = x.query(rule).index\n",
    "            if len(select_index) > 0:\n",
    "                y_select = y[select_index]\n",
    "                df = pd.Series()\n",
    "                df['组合策略'] = rule\n",
    "                df['好样本数'] = len(y_select) - y_select.sum()\n",
    "                df['好样本占比'] = df['好样本数'] / (total_count * (1 - total_bad_rate))\n",
    "                df['坏样本数'] = y_select.sum()\n",
    "                df['坏样本占比'] = df['坏样本数'] / (total_count * total_bad_rate)\n",
    "                df['命中数'] = df['好样本数'] + df['坏样本数']\n",
    "                df['命中率'] = df['命中数'] / total_count\n",
    "                df['坏率'] = df['坏样本数'] / df['命中数']\n",
    "                df['样本整体坏率'] = total_bad_rate\n",
    "                df['LIFT值'] = df['坏率'] / df['样本整体坏率']\n",
    "            else:\n",
    "                df = pd.Series({'组合策略': rule,'好样本数': 0,'好样本占比': 0.,'坏样本数': 0,'坏样本占比': 0.,'命中数': 0,'命中率': 0.,'坏率': 0.,'样本整体坏率': total_bad_rate,'LIFT值': 0.,})\n",
    "\n",
    "            rules = pd.concat([rules, pd.DataFrame(df).T]).reset_index(drop=True)\n",
    "\n",
    "        return rules[self.describe_columns]\n",
    "    \n",
    "    def insert_dt_rules(self, parsed_rules, end_row, start_col, save=None):\n",
    "        end_row, end_col = self.writer.insert_df2sheet(self.worksheet, parsed_rules, (end_row + 2, start_col))\n",
    "        \n",
    "        for c in ['好样本占比', '坏样本占比', '命中率', '坏率', '样本整体坏率', 'LIFT值']:\n",
    "            conditional_column = get_column_letter(start_col + parsed_rules.columns.get_loc(c))\n",
    "            self.writer.set_number_format(self.worksheet, f\"{conditional_column}{end_row - len(parsed_rules)}:{conditional_column}{end_row - 1}\", \"0.00%\")\n",
    "        for c in [\"坏率\", \"LIFT值\"]:\n",
    "            conditional_column = get_column_letter(start_col + parsed_rules.columns.get_loc(c))\n",
    "            self.writer.add_conditional_formatting(self.worksheet, f'{conditional_column}{end_row - len(parsed_rules)}', f'{conditional_column}{end_row - 1}')\n",
    "        \n",
    "        if save is not None:\n",
    "            end_row, end_col = self.writer.insert_pic2sheet(self.worksheet, save, (end_row + 1, start_col), figsize=(400, 300))\n",
    "        \n",
    "        return end_row, end_col\n",
    "        \n",
    "    def fit(self, x, y=None, max_depth=2, lift=3, max_samples=0.2, min_score=None, verbose=False, **kwargs):\n",
    "        y = x[self.target]\n",
    "        X_TE = self.encode_cat_features(x.drop(columns=[self.target]), y)\n",
    "        X_TE = X_TE.fillna(self.nan)\n",
    "        \n",
    "        self.feature_names = list(X_TE.columns)\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            decision_tree = DecisionTreeClassifier(max_depth=max_depth, **kwargs)\n",
    "            decision_tree = decision_tree.fit(X_TE, y)\n",
    "            \n",
    "            if (min_score is not None and decision_tree.score(X_TE, y) < min_score) or len(X_TE.columns) < max_depth:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                parsed_rules, remove = self.select_dt_rules(decision_tree, X_TE, y, lift=lift, max_samples=max_samples, labels=self.labels, verbose=verbose, save=f\"model_report/auto_mining_rules/combiner_rules_{i}.png\", drop=True)\n",
    "        \n",
    "                if len(parsed_rules) > 0:\n",
    "                    self.dt_rules = pd.concat([self.dt_rules, parsed_rules]).reset_index(drop=True)\n",
    "\n",
    "                    if self.writer is not None:\n",
    "                        if self.feature_map is not None and len(self.feature_map) > 0:\n",
    "                            parsed_rules[\"组合策略\"] = parsed_rules[\"组合策略\"].replace(self.feature_map, regex=True)\n",
    "                        self.end_row, _ = self.insert_dt_rules(parsed_rules, self.end_row, self.start_col, save=f\"model_report/auto_mining_rules/combiner_rules_{i}.png\")\n",
    "\n",
    "                X_TE = X_TE.drop(columns=remove)\n",
    "                self.decision_trees.append(decision_tree)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        y = x[self.target]\n",
    "        X_TE = self.encode_cat_features(x.drop(columns=[self.target]), y)\n",
    "        X_TE = X_TE.fillna(self.nan)\n",
    "        if self.dt_rules is not None and len(self.dt_rules) > 0:\n",
    "            parsed_rules = self.query_dt_rules(X_TE, y, parsed_rules=self.dt_rules)\n",
    "            if self.feature_map is not None and len(self.feature_map) > 0:\n",
    "                parsed_rules[\"组合策略\"] = parsed_rules[\"组合策略\"].replace(self.feature_map, regex=True)\n",
    "            return parsed_rules\n",
    "        else:\n",
    "            return pd.DataFrame(columns=self.describe_columns)\n",
    "    \n",
    "    def insert_all_rules(self, val=None, test=None):\n",
    "        parsed_rules_train = self.dt_rules.copy()\n",
    "        if self.feature_map is not None and len(self.feature_map) > 0:\n",
    "            parsed_rules_train[\"组合策略\"] = parsed_rules_train[\"组合策略\"].replace(self.feature_map, regex=True)\n",
    "        self.end_row, _ = self.writer.insert_value2sheet(self.worksheet, (self.end_row + 2, self.start_col), value=\"训练集决策树组合策略\")\n",
    "        self.end_row, _ = self.insert_dt_rules(parsed_rules_train, self.end_row, self.start_col)\n",
    "        \n",
    "        if val is not None:\n",
    "            parsed_rules_val = self.transform(val)\n",
    "            self.end_row, _ = self.writer.insert_value2sheet(self.worksheet, (self.end_row + 2, self.start_col), value=\"验证集决策树组合策略\")\n",
    "            self.end_row, _ = self.insert_dt_rules(parsed_rules_val, self.end_row, self.start_col)\n",
    "        \n",
    "        if test is not None:\n",
    "            parsed_rules_test = self.transform(test)\n",
    "            self.end_row, _ = self.writer.insert_value2sheet(self.worksheet, (self.end_row + 2, self.start_col), value=\"测试集决策树组合策略\")\n",
    "            self.end_row, _ = self.insert_dt_rules(parsed_rules_test, self.end_row, self.start_col)\n",
    "            \n",
    "    def save(self):\n",
    "        self.writer.save(self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ParseDecisionTreeRules at 0x7fe0983d2f10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdtr_instance = ParseDecisionTreeRules(target=target, max_iter=8)\n",
    "pdtr_instance.fit(train, lift=1., max_depth=1, max_samples=0.01, verbose=True, max_features=\"auto\")\n",
    "# pdtr_instance.insert_all_rules(test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdtr_instance.dt_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
